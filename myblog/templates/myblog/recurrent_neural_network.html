<!-- myblog/templates/myblog/polynomial_regression.html -->

{% extends 'myblog/base.html' %}
{% block title %}Рекуррентная нейронная сеть{% endblock %}

{% block content %}
  <style>
    .content-container {
      margin: 20px auto; /* Отступы со всех сторон и автоматическое выравнивание по центру */
      line-height: 2; /* Здесь 1.5 - это множитель текущего размера шрифта */
      max-width: 800px; /* Максимальная ширина контейнера */
    }

    .img-container {
      display: flex;
      justify-content: center; /* Выравнивание по горизонтали */
      align-items: center; /* Выравнивание по вертикали */
      margin-bottom: 20px; /* Дополнительный отступ снизу */
    }

    .img-container img {
      max-width: 100%; /* Максимальная ширина изображения */
      max-height: 100%; /* Максимальная высота изображения */
    }
  </style>

  <div class="content-container">
    <h2>Рекуррентная нейронная сеть</h2>

    <p>
    Рекуррентная нейронная сеть (RNN) - это класс нейронных сетей, который способен обрабатывать последовательные входные данные, учитывая их контекст и предыдущие состояния. RNN имеет внутреннее состояние или память, которое обновляется при обработке каждого элемента последовательности. Это позволяет RNN моделировать зависимости в данных, которые имеют последовательную структуру, такие как временные ряды, естественный язык и многое другое.    </p>

    <div class="img-container">
      <img class="img-fluid rounded" src="/media/neural_media/1_neu_gif.webp" alt="" width="600" height="400">
    </div>

    <p>
    Для реализации рекуррентной нейронной сети на основе датасета из Kaggle, мы используем библиотеки машинного обучения, такие как TensorFlow и Keras, специализированные на разработке и обучении нейронных сетей, а также библиотеку pandas для работы с данными.
    </p>

    <p>
    В качестве датасета мы выбрали данные о ценах на жилье в <a href="https://www.kaggle.com/datasets/simpleparadox/bostonhousingdataset?resource=download">Boston (Boston Housing Prices dataset)</a> из Kaggle. Разделяем данные на признаки (X) и целевую переменную (y). Для эффективного обучения модели признаки масштабируются с использованием StandardScaler(), что помогает привести их к одному масштабу и ускоряет процесс обучения.
    </p>

    <div class="img-container">
      <img class="img-fluid rounded" src="/media/neural_media/2_neu.png" alt="" width="600" height="400">
    </div>

    <p>
    Преобразуем данные для подачи в рекуррентную нейронную сеть. Для этого мы используем метод reshape() из библиотеки numpy, чтобы преобразовать данные в трехмерный массив, необходимый для работы с рекуррентными нейронными сетями.
    </p>

    <div class="img-container">
      <img class="img-fluid rounded" src="/media/neural_media/3_neu.png" alt="" width="600" height="400">
    </div>

    <p>
    Создаем модель рекуррентной нейронной сети с одним слоем SimpleRNN и одним выходным слоем Dense. Первый слой SimpleRNN использует функцию активации ReLU, а выходной слой не имеет функции активации, поскольку решается задача регрессии. Затем мы компилируем модель, указывая оптимизатор и функцию потерь.
    </p>

    <div class="img-container">
      <img class="img-fluid rounded " src="/media/neural_media/4_neu.png" alt="" width="600" height="400">
    </div>

    <p>
    Строим график обучения, отображая значения функции потерь на обучающей и валидационной выборках в зависимости от числа эпох обучения. Это позволяет нам оценить процесс обучения модели и проверить, есть ли переобучение или недообучение.
    </p>

    <div class="img-container">
      <img class="img-fluid rounded" src="/media/neural_media/5_neu.png" alt="" width="600" height="400">
    </div>

    <p>
    <div class="img-container">
      <img class="img-fluid rounded" src="/media/neural_media/6_neu.png" alt="" width="600" height="400">
    </div>

    <p>

    <div class="img-container">
      <img class="img-fluid rounded" src="/media/neural_media/7_neu.png" alt="" width="600" height="400">
    </div>

    <p>
    Вывод: Рекуррентная нейронная сеть успешно обучена на данных о ценах на жилье в Бостоне и показала хорошие результаты в прогнозировании цен. График обучения демонстрирует, что модель быстро сходится и не наблюдается переобучения. Это подтверждает эффективность применения рекуррентных нейронных сетей в задачах анализа временных последовательностей.
    </p>
  </div>
{% endblock %}
