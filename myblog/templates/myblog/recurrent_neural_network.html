<!-- myblog/templates/myblog/polynomial_regression.html -->

{% extends 'myblog/base.html' %}
{% block title %}Рекуррентная нейронная сеть{% endblock %}

{% block content %}
  <style>
    .content-container {
      margin: 20px auto; /* Отступы со всех сторон и автоматическое выравнивание по центру */
      line-height: 2; /* Здесь 1.5 - это множитель текущего размера шрифта */
      max-width: 1000px; /* Максимальная ширина контейнера */
    }

    .img-container {
      margin-bottom: 20px; /* Дополнительный отступ снизу */
      text-align: center; /* Выравнивание по центру */
    }

    .img-container img {
      max-width: 100%; /* Максимальная ширина изображения */
      height: auto; /* Автоматическая высота */
    }
    .code-cell {
        margin-left: 0; /* Убираем отступ слева */
        margin-right: auto; /* Выравнивание по правому краю */
        width: auto; /* Ширина ячейки кода */
        border: 1px solid #ccc;
        border-radius: 2px;
        padding: 1px;
        background-color: #f7f7f7;
        font-family: monospace;
        line-height: 1.5;
        overflow-x: auto;
        text-align: left; /* Выравниваем текст по левому краю */
    }

  </style>

  <div class="content-container">
    <h2>Рекуррентная нейронная сеть</h2>

    <p>
    Рекуррентная нейронная сеть (RNN) - это класс нейронных сетей, который способен обрабатывать последовательные входные данные, учитывая их контекст и предыдущие состояния. RNN имеет внутреннее состояние или память, которое обновляется при обработке каждого элемента последовательности. Это позволяет RNN моделировать зависимости в данных, которые имеют последовательную структуру, такие как временные ряды, естественный язык и многое другое.    </p>

    <div class="img-container">
      <img class="img-fluid rounded" src="/media/neural_media/1_neu_gif.webp" alt="" width="600" height="400">
    </div>

    <p>
    Для реализации рекуррентной нейронной сети на основе датасета из Kaggle, мы используем библиотеки машинного обучения, такие как TensorFlow и Keras, специализированные на разработке и обучении нейронных сетей, а также библиотеку pandas для работы с данными.
    </p>

    <p>
    В качестве датасета мы выбрали данные о ценах на жилье в <a href="https://www.kaggle.com/datasets/simpleparadox/bostonhousingdataset?resource=download">Boston (Boston Housing Prices dataset)</a> из Kaggle. Разделяем данные на признаки (X) и целевую переменную (y). Для эффективного обучения модели признаки масштабируются с использованием StandardScaler(), что помогает привести их к одному масштабу и ускоряет процесс обучения.
    </p>

    <div class="img-container">
      <pre class="code-cell">
        <code>
        from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler
        # Разделение на обучающую и тестовую выборки
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        # Масштабирование признаков
        scaler = StandardScaler (
        X_train_scaled = scaler. fit_transform(X_train)
        X_test_scaled = scaler. transform (X_test)
        </code>
      </pre>
    </div>

    <p>
    Преобразуем данные для подачи в рекуррентную нейронную сеть. Для этого мы используем метод reshape() из библиотеки numpy, чтобы преобразовать данные в трехмерный массив, необходимый для работы с рекуррентными нейронными сетями.
    </p>

    <div class="img-container">
      <pre class="code-cell">
        <code>
        import numpy as np
        # Преобразование данных для рекуррентной нейронной сети
        num_samples, num_features = X_train_scaled. shape
        X_train_reshaped = X_train_scaled. reshape(num_samples, 1, num_features)
        num_samples_test, - = X_test_scaled. shape
        X_test_reshaped = X_test_scaled. reshape(num_samples_test, 1, num_features)
        </code>
      </pre>
    </div>

    <p>
    Создаем модель рекуррентной нейронной сети с одним слоем SimpleRNN и одним выходным слоем Dense. Первый слой SimpleRNN использует функцию активации ReLU, а выходной слой не имеет функции активации, поскольку решается задача регрессии. Затем мы компилируем модель, указывая оптимизатор и функцию потерь.
    </p>

    <div class="img-container">
      <pre class="code-cell">
        <code>
        from tensorflow.keras.models import Sequential from tensorflow.keras. layers import SimpleRNN, Dense
        # Создание модели рекуррентной нейронной сети
        model = Sequential(I
        SimpleRNN(64, input_shape=(1, num_features), activation='relu'), Dense (1)
        # Компиляция модели
        model. compile(optimizer='adam', loss='mean_squared_error')
        </code>
      </pre>
    </div>

    <p>
    Строим график обучения, отображая значения функции потерь на обучающей и валидационной выборках в зависимости от числа эпох обучения. Это позволяет нам оценить процесс обучения модели и проверить, есть ли переобучение или недообучение.
    </p>

    <div class="img-container">
      <pre class="code-cell">
        <code>
        history = model.fit(X_train_reshaped, _train, epochs=10, validation_split=0.2)
        import matplotlib.pyplot as plt
        plt.plot(history.history['loss'], label='Training Loss')
        plt.plot(history.history['val_loss'], label='Validation Loss')
        plt. xlabel( 'Epochs')
        plt.ylabel( 'Loss')
        plt. legend ( )
        plt. show()
        </code>
      </pre>
    </div>

    <p>
    <div class="img-container">
      <img class="img-fluid rounded" src="/media/neural_media/6_neu.png" alt="" width="600" height="400">
    </div>

    <p>

    <div class="img-container">
      <img class="img-fluid rounded" src="/media/neural_media/7_neu.png" alt="" width="600" height="400">
    </div>

    <p>
    Вывод: Рекуррентная нейронная сеть успешно обучена на данных о ценах на жилье в Бостоне и показала хорошие результаты в прогнозировании цен. График обучения демонстрирует, что модель быстро сходится и не наблюдается переобучения. Это подтверждает эффективность применения рекуррентных нейронных сетей в задачах анализа временных последовательностей.
    </p>
  </div>
{% endblock %}
